\section{Introduction to network filesystems}

Network file systems allow files on a server to be shared and accessed over the network.
Several different protocols for network file systems have been designed over the years,
with the most well-known being Network File System (NFS) and 
Server Message Block (SMB).
% Common Internet File System (CIFS).
Though history and specifics of those protocols differ considerably, the common design
goal shared by both of them is to be transparent to the applications using them.
That is, applications and libraries should work identically on networked file systems
as they work on local file systems, without requiring any code changes or recompilation.

\subsection{NFS}

The NFS protocol originates from Sun Microsystems, where the initial implementation work for the
Unix 4.2 operating system was started in 1984~\cite{NFS}. Its original design goals were
transparent operation with existing programs by maintaining existing Unix file system
semantics, ability to recover from server reboots or crashes, and having reasonable
performance. Since then, extensions to the original protocol have been standardized
in several RFCs, with NFSv3~\cite{NFSv3RFC} in 1995 and NFSv4~\cite{NFSv4RFC},
bringing several improvements in performance, security and feature set~\cite{NFSv4Better}.

\subsection{SMB / CIFS}

The SMB protocol has a more complex history behind it. The protocol was initially designed
and implemented by IBM for the DOS operating system in the 80s
and ran over NetBIOS on the session layer and NBF (NetBIOS frames) on the network and transfer layers~\cite{CifsBook}.
In addition to being a file server, protocol, it is capable of sharing printers and serial ports over the network as well.
Further developments to the protocol were made by Microsoft.
In 1992 parts of the the protocol were specified in an X/Open standard~\cite{XopenSmbSpec}.
In 1996, Microsoft started using the Common Internet File System (CIFS) name for the protocol.

\section{Performance measurements}

As mentioned earlier, good performance was one of the design goals of the NFS protocol.
As a result, various benchmarks for NFS server implementations have been implemented.

\subsection{Postmark}
As most network file systems permit applications to transparently work with them,
a simple way of benchmarking network file system implementations is to run regular file system benchmarks over them.
One such instance is the Postmark benchmark, which is designed to have a workload similar to a mail or newsgroup server.
The benchmark exercises the performance of handling small files by simulating operations of a server which
stores mail on the disk as one file per message.
% The benchmark exercises the performance of handling small files by simulating operations on multiple "mailboxes"
% that are directories containing a large number of messages, each with its own file.
% FIXME: directories only came in later versions

The test starts with a number of initial files containing a random amount of data according to a configurable uniform random distribution.
Then a number of transactions are performed on the files; each transaction consists of two randomly selected operations.
The first operation is either a file creation or a file deletion, the second is either reading from a file or appending to a file.
For each operation, an random file is picked, independ of what while was picked for the other operation of the transaction.
File creations also write a random amount of initial content to the selected file.
Amount of data in the files (during initial creation and create or append operations) is kept within configurable limits.
There are also a handful of other configurable parameters, like initial number of files and ratio of operations to perform.
The pseudo-random number generator is fixed, so the benchmark with the same parameters should work identically on different systems.
Results from the benchmark consists of details on both the overall benchmark run and details for each operation type.
The rate of transactions per second in total seems to be the primary metric of the benchmark.
For each operation type, the number and rate of operations of that type is reported.
Additionally for the read and write operations, throughput numbers (in bytes/second) are provided as well.

The Postmark authors themselves have numbers comparing performance numbers for comparing local filesystems on both Unix and Windows
to specialized NetApp storage appliances connected over NFS and CIFS, respectively.
The Unix and Windows servers in the test were running on different hardware and file systems,
with details of the NetApp hardware not disclosed.
The results claim a transaction rate of 2x-3x for the networked storage compared to local filesystems.
While this sort of benchmark is somewhat questionable as the disks and other underlying storage hardware aren't equivalent,
it does show that the neither the network file system protocols nor clients in either operating system have
bottlenecks that would limit the performance.

The benchmark has been popular in both regular and networked file system benchmarks;
for instance the study ``A Nine Year Study of File System and Storage Benchmarking''~\cite{MetaStudy} from 2008
surveyed 106 file system and storage related papers from years 1999--2006, and Postmark was used in 30 papers.
However, it also raises some criticism on the benchmark.
In particular, the workload of the benchmark doesn't scale well with the increases in the speed of hardware;
in one extreme case the benchmark completed in under a tenth of a second on modern hardware when the default parameters
of the benchmark were used.
Since the defaults for the benchmark run for a too short time to give accurate results,
the papers' authors picked their own parameters.
This makes it difficult to compare Postmark results to others' results,
or even non-reproducible, as many papers failed to report the parameters used in the necessary degree.

\subsection{LADDIS}
One instance of such a benchmark is LADDIS from the 90s~\cite{LADDIS}, designed and named after by
several NFS server vendors at that time (\underline{L}egato Systems, \underline{A}uspex Systems, \underline{D}ata General,
\underline{D}igital Equipment, \underline{I}nterphase and \underline{S}un Microsystems).
It is designed to be a standard benchmark for making performance comparisons across different NFS server implementations
or configurations.
The LADDIS benchmarking software is a synthetic workload generator that talks to the NFS server directly,
without any dependency on the NFS client implementation of the system generating the workload.
The implementation of the benchmark consists of making randomly selected NFS protocol operations
(for instance, creating deleting or reading from a file)
to the server.
The distribution of which operations to perform

\section{Performance differences between protocol revisions} \label{sect:NFSv41}

As was mentioned earlier, good performance was one of the design goals for the NFS protocol,
and since the original protocol implementation additional efforts have been spent improving the performance of the protocol.
Naturally, new versions of the protocol raise the question of how much does an improved protocol revision actually help.
For version 4.1 of the NFS protocol, this has been investigated in the aptly-named article ``Newer Is Sometimes Better: An Evaluation of NFSv4.1''~\cite{NFSv4Better}, which compares NFSv3, NFSv4 and NFSv4.1 performance of the Linux NFS server implementation.
Their test setup was done on a 10GbE network with five client machines and one server machine, running identical enterprise-class hardware.
The NFS server was equipped with fast solid-state disks in RAID-0 to keep the focus of the tests on the protocol level performance.
In addition to comparing performance with multiple clients, the test setup included possibility of adding artificial network latency to the test.

\subsection{NFSv4.1 delegations}
According on the team's analysis on their results, a significant improvement that the version 4.1 of the NFS protocol brings is the \emph{delegation
mechanism} to improve the effectiveness of client-side caching.
Consider an implementation that wishes to do read caching and simultaneously maintain coherency in case of other clients
concurrently writing to the same file.
In the stateless NFSv3 protocol, the client doing the reads must periodically ask the server for the last-modification timestamp of the file in order to notice other clients writing to the file.
The read delegation feature of NFSv4.1 allows a better way of managing caching.
The server now maintains state for opened files, so a lone client reading files can proceed with full caching,
and in case some other client starts writing concurrently, the server will notify the client and recall the delegation.

For concrete numbers on the benefits of delegations, a microbenchmark of repeatedly reading (10 times per file) 10 000 small files performs X times faster.
On the protocol level, NFSv3 performed 20 times the amount of NFS requests compared to NFSv4.1 with delegations enabled.
% XXX this microbenchmark is different from the one in the graph below.

However, the delegations feature is not an universal improvement.
The need for OPEN and CLOSE requests to maintain state of open files on the server can significantly increase the amount of protocol requests made by NFSv4.1 compared to NFSv3.
For instance, the file server workload of the Filebench benchmark caused an increase of 56\% in the number of protocol requests made by NFSv4.1 over NFSv3.
This translated into a 8--18\% of slowdown.
% The biggest difference was in the zero-delay network, where V4.1p was 15% slower

\begin{figure}[h]
\centering\includegraphics[width=0.5\textwidth]{images/nfsv41better-reading-small-files.png}
\caption{Figure 6 from ``Newer Is Sometimes Better: An Evaluation of NFSv4.1''~\cite{NFSv4Better}.}
% Section 4.1 Read Small Files
\end{figure}

\section{Analysis of a production file server}

Another approach of analysing network file systems is to look at how the actual users of such systems are using it.
One such example comes from ``Measurement and Analysis of Large-scale Network File System Workloads''~\cite{NetApp} done by NetApp,
a company developing network storage products.
The study was done on the corporate's own internal file servers by collecting live packet captures of CIFS protocol traffic.
Data was collected from two different servers, one serving users and one serving engineering users, creating two different datasets.
Compared to other ways of collecting data on file server usage, such as analysing static file system snapshots of the file server,
the use of network traffic as a data source allows analysis of changes to the file system over time.
Since user authentication in the test environment was done by a separate Kerberos protocol,
only IP addresses were used to correlate CIFS sessions to actual unique users of the system.

Previously in section \ref{sect:NFSv41} we discussed the delegations feature NFSv4.1 which would improve performance in the case of files not being concurrently accessed by multiple clients.
In the NetApp datasets, even non-concurrent sharing of files was relatively uncommon: 23.9\% and 2.9\% files were ever opened by user.
And with concurrent sharing, the numbers drop down to 7.3\% and 0.3\% respectively.
So the tradeoffs involved in the NFSv4.1 delegations feature seem justified by these results.
Although the result was obtained in a CIFS environment instead of NFS.
the authors claim that the results are not unique to CIFS.

\section{Conclusions}
NFS and SMB/CIFS are widely-used network file system protocols.
Both of them are complex by the nature of having several protocol revisions developed over the previous three decades.
Good performance is a primary design goal for them, and properly evaluating performance requires good benchmarks.
Improvements made in newer protocol revisions (NFSv4.1 for example) can boost performance in common cases,
but can bring
